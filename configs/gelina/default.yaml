
hydra:
  job:
    chdir: false
    env_set:
      TRITON_CACHE_DIR: "${oc.env:HOME}/.triton/cache" 

defaults:
  - _self_
  - datamodule: default
  - optimizer:  adamw             # configs/optimizer/adamw.yaml
  - attentive_rnn: gla            # configs/attentive_rnn/gla.yaml

seed_everything: 123

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: gpu
  precision: bf16-mixed
  strategy: ddp
  devices: 1
  use_distributed_sampler: false
  max_epochs: 100
  gradient_clip_val: 1.0
  val_check_interval: 1.0
  limit_train_batches: 10000
  accumulate_grad_batches: 1
  log_every_n_steps: 1

  logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    project: lina
    name: gelina-beat-default
    save_dir: checkpoints/GELINA

  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_loss
      dirpath: checkpoints/pt_speech/${trainer.logger.name}
      filename: checkpoint_{epoch}_{step}_{val_loss_avg:.4f}
      save_top_k: 1
      save_last: true
    - _target_: pytorch_lightning.callbacks.ModelSummary
      max_depth: 2

model:
  _target_: packages.gelina.src.gelina.gelina_trainer.TrainGeLina
  
  n_warmup_steps: 500
  n_training_steps: 50000
  learning_rate: 2e-4

  n_codebook_speech: 4096
  n_codebook_motion: 512
  n_special_token_in: 3
  n_special_token_out: 3
  loss_weight: {'speech': 1.0, 'motion': 1.0}
  n_txt_vocab: 256
  d_model: 1024
  mode: bimodal
  pe_mode: 'modality_agnostic'

  quant_layer_speech: [0]
  quant_layer_motion: [0, 1, 2, 3, 4, 5]

  txt_encoder:
    _target_: packages.common.src.common.blocks.encoder.TextEncoder
    dim: ${model.d_model}
    heads: 4
    n_layers: 6
    dropout: 0.1

  attentive_rnn: ${attentive_rnn}   # pulled from defaults

  logits_head_motion: 
    _target_: packages.gelina.src.gelina.components.logit_heads.SimpleLogitHead
    d_model: ${model.d_model}
    n_quant: 6
    n_codebook: ${model.n_codebook_motion}
    n_special_token_out: ${model.n_special_token_out}

  logits_head_speech: 
    _target_: packages.gelina.src.gelina.components.logit_heads.SimpleLogitHead
    d_model: ${model.d_model}
    n_quant: 1
    n_codebook: ${model.n_codebook_speech}
    n_special_token_out: ${model.n_special_token_out}
