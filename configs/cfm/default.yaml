# config/gematcha/base.yaml

hydra:
  job:
    chdir: false

defaults:
  - _self_
  - decoder: default
  - cfm: default
  - optimizer: default
  - datamodule: beat_latents 

seed_everything: 123

model:
  _target_: packages.cfm.src.cfm.cfm_trainer.TrainCFM
  n_feats_in: 1024 # input conditioning dim
  n_feats_out: 157 # projected conditioning dim
  pose_dim: 157 
  out_size: ${model.pose_dim} # generated motion dim
  decoder:       ${decoder}
  cfm:           ${cfm}
  optimizer_cfg: ${optimizer}
  loss_fn: "mse_loss"
  scheduler_cfg: null
  joints: full_body
  sample_factor: 4
  use_interpolation: false
  cond_dropout: 0.1
  vel_weight: 0.0

trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: gpu
  precision: bf16-mixed
  strategy: ddp_find_unused_parameters_true #ddp
  devices: 1
  use_distributed_sampler: true
  sync_batchnorm: true
  max_epochs: 500
  gradient_clip_val: 1.0
  val_check_interval: 1.0
  limit_train_batches: 10000
  accumulate_grad_batches: 1
  log_every_n_steps: 1

  logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    project: CFM
    name: cfm-157
    save_dir: checkpoints/CFM

  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: val_loss
      dirpath: checkpoints/CFM/${trainer.logger.name}
      filename: checkpoint_{epoch}_{step}_{val_loss:.4f}
      save_top_k: 1
      save_last: true

    - _target_: pytorch_lightning.callbacks.ModelSummary
      max_depth: 2
